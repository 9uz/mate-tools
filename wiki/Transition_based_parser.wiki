#This page describes the usage of our transition-based parser (Joint Pos-Tagging / Graph-based completion model) 

= Transition-based parser including a pos-tagger and graph-based model =

Please, note that the parser is a research parser and we will provide later versions that use less memory and disc space. It is also not exactly the version, we used for our papers (Bohnet and Kuhn, 2012). It is most similar to the parser in (Bohnet and Nivre, 2012). However, I fixed a few bugs and improved the speed.

For the training settings of different language, we would recommand to have a look on our paper (Bohnet and Nivre, 2012). For the performance of the settings of the completion model, I recommand (Bohnet and Kuhn, 2012). 

 
==Training ==

  # For the training, a computer with 18G free main memory is needed as we jackknife 10 taggers in the training phase; I recommand to use a newer  Intel CPU with a minimum number of 4 cores better 6. I use currently mostly a (cheap) desktop CPU (Intel, 3930K, 6core, 3.2 Ghz) for the training. The training is carried out within 24 hours (beam 40, English) on this type of machine. Warning: AMD CPUs even with many cores seem not to work so well, it might take up to several days. 
  # Training and parsing settings
|| *Options*               || *Description* ||
|| -train file-name        || train-corpus name||
|| -test file-name>        || test-corpus name||
|| -eval file-name>        || evaluation-corpus name||
|| -i number               || number of training iterations ||
|| -beam number            || beam size ||
|| -hsize number           || size of hash kernel ||
|| -1st a                  || use first oder factor  ||
|| -2nd abcd               || use second order factors (each letter denotes a factor)  ||
|| -2nd abc                || use third order factors (each letter denotes a factor)  ||
|| -x train:test           || train and test the pos taggers ||
  
  #3 Example training command:
{{{
xxx
}}} 


 